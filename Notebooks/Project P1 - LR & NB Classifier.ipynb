{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1\n",
    "# Training Data\n",
    "train_data_jsonl = open('train.data.jsonl', 'r')\n",
    "train_label = open('train.label.json', 'r')\n",
    "\n",
    "# Dev Data\n",
    "dev_data_jsonl = open('dev.data.jsonl', 'r')\n",
    "dev_label = open('dev.label.json', 'r')\n",
    "\n",
    "# Test Data\n",
    "test_data_jsonl = open('test.data.jsonl', 'r')\n",
    "\n",
    "\n",
    "# Task 2 Covid Data\n",
    "covid_data_jsonl = open('covid.data.jsonl', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweet ID (Key)\n",
    "# USer ID\n",
    "# Follower Count\n",
    "# Text\n",
    "# Time Posted\n",
    "# Parent Tweets ID (If Any)\n",
    "# Child tweets ID (If any)\n",
    "\n",
    "\n",
    "# Find BERT tokenize max size\n",
    "bert_token_list = []\n",
    "\n",
    "tweet_dict = {}\n",
    "\n",
    "train_label_json = json.load(train_label)\n",
    "dev_label_json = json.load(dev_label)\n",
    "\n",
    "# Make label 1 or 0\n",
    "# 0 for non-rumour\n",
    "def binary_label(label):\n",
    "    if label == 'non-rumour':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def jsonl_to_list(jsonl, labels):\n",
    "    out_list = []\n",
    "    responses_list = []\n",
    "    reply_list =[]\n",
    "    \n",
    "    for line in jsonl:\n",
    "        data = json.loads(line)\n",
    "        responses = 0\n",
    "\n",
    "        for tweet_data in data:\n",
    "            \n",
    "            tweet_id = tweet_data['id']\n",
    "            user_id = tweet_data['user']['id']\n",
    "            follower_count = tweet_data['user']['followers_count']\n",
    "            \n",
    "            \n",
    "            text = tweet_data['text']            \n",
    "            time = tweet_data['created_at']\n",
    "            parent = tweet_data['in_reply_to_status_id']\n",
    "\n",
    "\n",
    "            tweet_dict[tweet_id] = {'user_id' : user_id,\n",
    "                                   'follower_count' : follower_count,\n",
    "                                   'text' : text,\n",
    "                                   'time': time,\n",
    "                                   'parent': parent}\n",
    "            \n",
    "            \n",
    "            # get label and conver to 0 or 1\n",
    "            \n",
    "            try:\n",
    "                label = binary_label(labels[str(tweet_id)])\n",
    "                out_list.append([tweet_id, text, time, parent, label, follower_count, user_id])\n",
    "            except KeyError:\n",
    "                responses += 1\n",
    "                reply_list.append([tweet_id, text, time, parent, follower_count, user_id])\n",
    "                continue\n",
    "                \n",
    "        \n",
    "        responses_list.append(responses)\n",
    "    return out_list, responses_list, reply_list\n",
    "\n",
    "\n",
    "\n",
    "# test data\n",
    "def no_label_json(jsonl):\n",
    "    output = []\n",
    "    for line in jsonl:\n",
    "\n",
    "        data = json.loads(line)\n",
    "        \n",
    "        for tweet_data in data:\n",
    "\n",
    "            tweet_id = tweet_data['id']\n",
    "            user_id = tweet_data['user']['id']\n",
    "            follower_count = tweet_data['user']['followers_count']\n",
    "            text = tweet_data['text']\n",
    "            time = tweet_data['created_at']\n",
    "            parent = tweet_data['in_reply_to_status_id']\n",
    "\n",
    "\n",
    "            tweet_dict[tweet_id] = {'user_id' : user_id,\n",
    "                                   'follower_count' : follower_count,\n",
    "                                   'text' : text,\n",
    "                                   'time': time,\n",
    "                                   'parent': parent}\n",
    "\n",
    "            output.append([tweet_id, text, time, parent, follower_count, user_id])\n",
    "    return output\n",
    "    \n",
    "train_list, train_responses, train_reply = jsonl_to_list(train_data_jsonl, train_label_json)\n",
    "dev_list, dev_responses, dev_reply = jsonl_to_list(dev_data_jsonl, dev_label_json)\n",
    "\n",
    "\n",
    "\n",
    "test_list = no_label_json(test_data_jsonl)\n",
    "covid_list = no_label_json(covid_data_jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Dataframes\n",
    "\n",
    "train_df = DataFrame(train_list, columns=['tweet_id', 'text', 'time', 'parent', 'label', 'follower_count', 'user_id'])\n",
    "train_df['responses'] = np.asarray(train_responses)\n",
    "\n",
    "train_reply_df = DataFrame(train_reply, columns=['tweet_id', 'text', 'time', 'parent', 'follower_count', 'user_id'])\n",
    "\n",
    "\n",
    "dev_df = DataFrame(dev_list, columns=['tweet_id', 'text', 'time', 'parent', 'label', 'follower_count', 'user_id'])\n",
    "dev_df['responses'] = np.asarray(dev_responses)\n",
    "\n",
    "dev_reply_df = DataFrame(dev_reply, columns=['tweet_id', 'text', 'time', 'parent', 'follower_count', 'user_id'])\n",
    "\n",
    "test_df = DataFrame(test_list, columns=['tweet_id', 'text', 'time', 'parent', 'follower_count', 'user_id'])\n",
    "\n",
    "# Task 2\n",
    "covid_df = DataFrame(covid_list, columns=['tweet_id', 'text', 'time', 'parent', 'follower_count', 'user_id'])\n",
    "\n",
    "\n",
    "# Merged DF\n",
    "frames = [train_df, dev_df]\n",
    "\n",
    "merged_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment_score_ind(text):\n",
    "\n",
    "    return sid.polarity_scores(text)['compound']\n",
    "\n",
    "def sent_dict(df):\n",
    "    parent_ids = list(df['parent'].unique())\n",
    "    sentiment_dict = {}\n",
    "    for parent in parent_ids:\n",
    "        replies = df[df['parent'] == parent]['text']\n",
    "\n",
    "        total_sent = []\n",
    "        for tweet in replies:\n",
    "            score = get_sentiment_score_ind(tweet)\n",
    "            total_sent.append(score)\n",
    "\n",
    "        mean = np.mean(total_sent)\n",
    "#         median = np.median(total_sent)\n",
    "        sentiment_dict[parent] = mean\n",
    "    return sentiment_dict\n",
    "\n",
    "def senti_results(df, label, senti_dict):\n",
    "    out_list = []\n",
    "    for tw in list(df[df['label'] == label]['tweet_id']):\n",
    "        try:\n",
    "            out_list.append(senti_dict[tw])\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Sentiment of Replies\n",
    "# train_senti_dict = sent_dict(train_reply_df) \n",
    "# dev_senti_dict = sent_dict(dev_reply_df) \n",
    "\n",
    "# train_rumour_reply_sent = senti_results(train_df, 1, train_senti_dict)\n",
    "# train_nonrumour_reply_sent = senti_results(train_df, 0, train_senti_dict)\n",
    "# dev_rumour_reply_sent = senti_results(dev_df, 1, dev_senti_dict)\n",
    "# dev_nonrumour_reply_sent = senti_results(dev_df, 0, dev_senti_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = list(train_df.text.values)\n",
    "train_labels = list(train_df.label.values)\n",
    "dev_sentences = list(dev_df.text.values)\n",
    "dev_labels = list(dev_df.label.values)\n",
    "test_sentences = list(test_df.text.values)\n",
    "\n",
    "merged_sentences = list(merged_df.text.values)\n",
    "merged_labels = list(merged_df.label.values)\n",
    "\n",
    "test_text = list(test_df.text.values)\n",
    "\n",
    "# BoW Model\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=0, lowercase=False)\n",
    "# vectorizer.fit(train_sentences)\n",
    "vectorizer.fit(merged_sentences)\n",
    "\n",
    "X_train = vectorizer.transform(merged_sentences)\n",
    "y_train = merged_labels\n",
    "\n",
    "\n",
    "X_test = vectorizer.transform(test_sentences)\n",
    "# X_train = vectorizer.transform(train_sentences)\n",
    "# y_train = train_labels\n",
    "# X_dev = vectorizer.transform(dev_sentences)\n",
    "# y_dev = dev_labels\n",
    "# len(vectorizer.vocabulary_)\n",
    "\n",
    "# vectorizer.transform(sentences).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRclassifier = LogisticRegression()\n",
    "LRclassifier.fit(X_train, y_train)\n",
    "\n",
    "SGDclass = SGDClassifier()\n",
    "SGDclass.fit(X_train, y_train)\n",
    "\n",
    "NBclassifier = MultinomialNB()\n",
    "NBclassifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# score = classifier.score(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_dev' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3be116acf95f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# lr_pred_test = LRclassifier.predict(X_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlr_pred_dev_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLRclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_dev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# sg_pred_test = SGDclass.predict(X_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msg_pred_dev_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSGDclass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_dev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_dev' is not defined"
     ]
    }
   ],
   "source": [
    "# lr_pred_test = LRclassifier.predict(X_test)\n",
    "lr_pred_dev_prob = LRclassifier.predict_proba(X_dev)\n",
    "\n",
    "# sg_pred_test = SGDclass.predict(X_test)\n",
    "sg_pred_dev_prob = SGDclass.predict_proba(X_dev)\n",
    "\n",
    "# nb_pred_test = NBclassifier.predict(X_test)\n",
    "nb_pred_dev_prob = NBclassifier.predict_proba(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_label(num):\n",
    "    if num == 0:\n",
    "        return 'non-rumour'\n",
    "    else:\n",
    "        return 'rumour'\n",
    "\n",
    "out_label = []\n",
    "\n",
    "for num in list(nb_pred_test):\n",
    "    out_label.append(class_label(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_label\n",
    "# id_list = [str(i) for i in list(test_df.tweet_id)]\n",
    "# out_dict = {}\n",
    "\n",
    "# for i, t in enumerate(id_list):\n",
    "#     out_dict[t] = out_label[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"test_out_nb.json\", \"w\") as outfile: \n",
    "#     json.dump(out_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dev set statistics\n",
    "print(\"LR Model\")\n",
    "print(\"precision:\", precision_score(y_dev, lr_pred_dev))\n",
    "print(\"recall:\", recall_score(y_dev, lr_pred_dev))\n",
    "print(\"f1:\", f1_score(y_dev, lr_pred_dev))\n",
    "\n",
    "# Dev set statistics\n",
    "print(\"SG Model\")\n",
    "print(\"precision:\", precision_score(y_dev, sg_pred_dev))\n",
    "print(\"recall:\", recall_score(y_dev, sg_pred_dev))\n",
    "print(\"f1:\", f1_score(y_dev, sg_pred_dev))\n",
    "\n",
    "\n",
    "# Dev set statistics\n",
    "print(\"NB Model\")\n",
    "print(\"precision:\", precision_score(y_dev, nb_pred_dev))\n",
    "print(\"recall:\", recall_score(y_dev, nb_pred_dev))\n",
    "print(\"f1:\", f1_score(y_dev, nb_pred_dev))\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If the reply sentiment score is lower than -0.1, increase prob of rumour\n",
    "# for t_id in train_senti_dict.keys():\n",
    "#     try:\n",
    "#         if train_senti_dict[t_id] <= -0.1:\n",
    "#             edit = pred_dev_dict[t_id]\n",
    "#             edit[1] = edit[1] + 0.4\n",
    "#             pred_dev_dict[t_id] = edit\n",
    "#     except KeyError:\n",
    "#         continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
